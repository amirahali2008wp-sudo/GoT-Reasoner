from openai import OpenAI
import json
import time
import os

class GoT_Reasoner:
    """
    ÛŒÚ© Ú†Ø§Ø±Ú†ÙˆØ¨ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ø± Ù¾Ø§ÛŒÙ‡ Ú¯Ø±Ø§Ù ÙÚ©Ø± Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ù…Ø³Ø§Ø¦Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡.
    """
    def __init__(self, client, model_name, problem_statement):
        self.client = client
        self.model_name = model_name
        self.problem = problem_statement
        self.graph = {"root": {"thought": "Ø´Ø±ÙˆØ¹ Ù…Ø³Ø¦Ù„Ù‡", "score": 0, "parent": None, "op": "initial"}}
        self.node_counter = 0
        print(f"ğŸš€ Ù…ÙˆØªÙˆØ± Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ú¯Ø±Ø§Ù ÙÚ©Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯ Ø¨Ø§ Ù…Ø¯Ù„: {self.model_name}")
        print(f"ğŸ¤” Ù…Ø³Ø¦Ù„Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ù„: {self.problem}")

    def _call_llm(self, prompt_text, system_message="Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ùˆ ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø± Ù‡Ø³ØªÛŒØ¯.", is_json=False):
        """ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…Ø¯Ù„ OpenAI."""
        try:
            response_format = {"type": "json_object"} if is_json else {"type": "text"}
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {'role': 'system', 'content': system_message},
                    {'role': 'user', 'content': prompt_text},
                ],
                temperature=0.7,
                response_format=response_format
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ API Ø±Ø® Ø¯Ø§Ø¯: {e}")
            return ""

    def _add_node(self, thought, score, parent="root", op="initial"):
        """Ø§ÙØ²ÙˆØ¯Ù† ÛŒÚ© ÙÚ©Ø± Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ú¯Ø±Ø§Ù."""
        node_id = f"node_{self.node_counter}"
        self.graph[node_id] = {"thought": thought, "score": score, "parent": parent, "operation": op}
        self.node_counter += 1
        print(f"âœ… ÙÚ©Ø± Ø¬Ø¯ÛŒØ¯ '{node_id}' Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø² {score:.2f} Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯: '{thought[:50]}...'")

    def _needs_complex_reasoning(self):
        """
        ØªØ´Ø®ÛŒØµ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø¢ÛŒØ§ Ù…Ø³Ø¦Ù„Ù‡ Ø¨Ù‡ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ø®ÛŒØ±.
        """
        prompt = f"""
        Ø¨Ù‡ Ø³ÙˆØ§Ù„ Ø²ÛŒØ± Ø¯Ù‚Øª Ú©Ù†:
        "{self.problem}"
        Ø¢ÛŒØ§ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ Ù†ÛŒØ§Ø² Ø¨Ù‡ ÙÚ©Ø± Ú©Ø±Ø¯Ù† Ú†Ù†Ø¯ Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒØŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ ÛŒØ§ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¹Ù…ÛŒÙ‚ Ø¯Ø§Ø±Ø¯ØŒ ÛŒØ§ ÛŒÚ© Ø³ÙˆØ§Ù„ Ø³Ø§Ø¯Ù‡ Ùˆ ÙˆØ§Ù‚Ø¹ÛŒ (factual) Ø§Ø³Øª Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ù‡ Ø¢Ù† Ù¾Ø§Ø³Ø® Ø¯Ø§Ø¯ØŸ
        Ù¾Ø§Ø³Ø® Ø±Ø§ ÙÙ‚Ø· Ø¨Ø§ ÛŒÚ© Ú©Ù„Ù…Ù‡ Ø¨Ø¯Ù‡: YES ÛŒØ§ NO.
        """
        response = self._call_llm(prompt, "Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ®ØµØµ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ¸Ø§ÛŒÙ Ù‡Ø³ØªÛŒØ¯.")
        return "YES" in response.upper()

    def evaluate_thought_quality(self, thought_candidate):
        """
        Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ ÛŒÚ© ÙÚ©Ø± Ú†Ù‚Ø¯Ø± Ø¨Ù‡ Ø­Ù„ Ù…Ø³Ø¦Ù„Ù‡ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        print(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ÙÚ©Ø±: '{thought_candidate[:60]}...'")

        evaluation_prompt = f"""
        ØµÙˆØ±Øª Ù…Ø³Ø¦Ù„Ù‡ Ø§ÛŒÙ† Ø§Ø³Øª: "{self.problem}"
        ÙÚ©Ø± ÛŒØ§ Ù‚Ø¯Ù… Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ø¢Ù† Ø§ÛŒÙ† Ø§Ø³Øª: "{thought_candidate}"

        Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ù…Ù†Ø·Ù‚â€ŒØ¯Ø§Ù†ØŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù† Ú©Ù‡ Ø§ÛŒÙ† ÙÚ©Ø± Ú†Ù‚Ø¯Ø± Ø¨Ù‡ Ø­Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø³Ø¦Ù„Ù‡ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ Ø¢ÛŒØ§ ÛŒÚ© Ù‚Ø¯Ù… Ù…Ø¹ØªØ¨Ø± Ùˆ Ù…ÙÛŒØ¯ Ø§Ø³ØªØŸ
        Ø§Ø² Û± ØªØ§ Û±Û° Ø¨Ù‡ Ø¢Ù† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø¯Ù‡.
        Ù¾Ø§Ø³Ø® Ø±Ø§ ÙÙ‚Ø· Ø¯Ø± Ø§ÛŒÙ† ÙØ±Ù…Øª JSON Ø§Ø±Ø§Ø¦Ù‡ Ø¨Ø¯Ù‡: {{"score": <Ø¹Ø¯Ø¯_Ø§Ù…ØªÛŒØ§Ø²>, "reason": "<Ø¯Ù„ÛŒÙ„_Ù…Ø®ØªØµØ±>"}}
        """
        evaluator_response = self._call_llm(evaluation_prompt, "Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø·Ù‚ÛŒ Ùˆ Ø³Ø®Øªâ€ŒÚ¯ÛŒØ± Ù‡Ø³ØªÛŒØ¯.", is_json=True)

        try:
            eval_json = json.loads(evaluator_response)
            return float(eval_json.get("score", 0))
        except (json.JSONDecodeError, TypeError, ValueError):
            print(f"âš ï¸ Ù¾Ø§Ø³Ø® Ø§Ø±Ø²ÛŒØ§Ø¨ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯: {evaluator_response}")
            return 0

    def generate_initial_thoughts(self, num_ideas=3):
        """ØªÙˆÙ„ÛŒØ¯ Ø§ÙˆÙ„ÛŒÙ† Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ø­Ù„ Ù…Ø³Ø¦Ù„Ù‡."""
        prompt = f"""
        Ù…Ø³Ø¦Ù„Ù‡ Ø§ÛŒÙ† Ø§Ø³Øª: "{self.problem}"
        Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ø­Ù„ Ø§ÛŒÙ† Ù…Ø³Ø¦Ù„Ù‡ØŒ {num_ideas} Ø§ÛŒØ¯Ù‡ ÛŒØ§ Ù‚Ø¯Ù… Ø§ÙˆÙ„ÛŒÙ‡ Ù…ØªÙØ§ÙˆØª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯Ù‡.
        Ù¾Ø§Ø³Ø® Ø¨Ø§ÛŒØ¯ ÛŒÚ© Ù„ÛŒØ³Øª JSON Ø§Ø² Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ Ø¨Ø§Ø´Ø¯. Ù…Ø«Ø§Ù„: ["Ù‚Ø¯Ù… Ø§ÙˆÙ„ Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡...", "Ø´Ø§ÛŒØ¯ Ø¨Ù‡ØªØ± Ø¨Ø§Ø´Ø¯ Ø¨Ø§..."]
        """
        ideas_response = self._call_llm(prompt, "Ø´Ù…Ø§ ÛŒÚ© Ø§ÛŒØ¯Ù‡â€ŒÙ¾Ø±Ø¯Ø§Ø² Ø®Ù„Ø§Ù‚ Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ù…Ø³Ø¦Ù„Ù‡ Ù‡Ø³ØªÛŒØ¯.", is_json=True)
        try:
            thoughts = json.loads(ideas_response)
            if isinstance(thoughts, dict) and thoughts.get('thoughts'): thoughts = thoughts['thoughts'] # for compatibility

            for t in thoughts:
                score = self.evaluate_thought_quality(t)
                self._add_node(t, score)
        except (json.JSONDecodeError, TypeError, KeyError):
            print("âŒ ØªÙˆÙ„ÛŒØ¯ Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")

    def refine_thought(self, parent_node_id):
        """Ù¾Ø§Ù„Ø§ÛŒØ´ Ùˆ ØªÚ©Ù…ÛŒÙ„ ÛŒÚ© ÙÚ©Ø± Ù…ÙˆØ¬ÙˆØ¯."""
        parent_thought = self.graph[parent_node_id]["thought"]
        prompt = f"""
        Ù…Ø³Ø¦Ù„Ù‡: "{self.problem}"
        ÙÚ©Ø± ÙØ¹Ù„ÛŒ Ø§ÛŒÙ† Ø§Ø³Øª: "{parent_thought}"
        Ø§ÛŒÙ† ÙÚ©Ø± Ø±Ø§ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ú©Ø§Ù…Ù„â€ŒØªØ± ÛŒØ§ ØµØ­ÛŒØ­â€ŒØªØ± Ú©Ù† ÛŒØ§ Ù‚Ø¯Ù… Ù…Ù†Ø·Ù‚ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø±Ø§ Ø¨Ù‡ Ø¢Ù† Ø§Ø¶Ø§ÙÙ‡ Ù†Ù…Ø§.
        Ù…Ù‡Ù…: ÙÙ‚Ø· Ù…ØªÙ† ÙÚ©Ø± Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†.
        """
        refined_thought = self._call_llm(prompt, "Ø´Ù…Ø§ ÛŒÚ© Ù…ØªÙÚ©Ø± Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù…Ù†Ø·Ù‚ÛŒ Ù‡Ø³ØªÛŒØ¯.")
        if refined_thought:
            score = self.evaluate_thought_quality(refined_thought)
            self._add_node(refined_thought, score, parent=parent_node_id, op="refine")

    def aggregate_thoughts(self, node_id_1, node_id_2):
        """ØªØ±Ú©ÛŒØ¨ Ø¯Ùˆ Ø®Ø· ÙÚ©Ø±ÛŒ Ù…ØªÙØ§ÙˆØª."""
        thought1 = self.graph[node_id_1]["thought"]
        thought2 = self.graph[node_id_2]["thought"]
        prompt = f"""
        Ù…Ø³Ø¦Ù„Ù‡: "{self.problem}"
        Ø¯Ùˆ Ø§ÛŒØ¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ø¢Ù† ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯:
        Ø§ÛŒØ¯Ù‡ Ø§Ù„Ù: "{thought1}"
        Ø§ÛŒØ¯Ù‡ Ø¨: "{thought2}"
        Ø¨Ù‡ØªØ±ÛŒÙ† Ø¬Ù†Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡Ø± Ø¯Ùˆ Ø§ÛŒØ¯Ù‡ Ø±Ø§ ØªØ±Ú©ÛŒØ¨ Ú©Ù† ØªØ§ ÛŒÚ© ÙÚ©Ø± ÛŒØ§ Ø±Ø§Ù‡â€ŒØ­Ù„ ØªØ±Ú©ÛŒØ¨ÛŒ Ù‚ÙˆÛŒâ€ŒØªØ± Ø¨Ø³Ø§Ø²ÛŒ.
        Ù…Ù‡Ù…: ÙÙ‚Ø· Ù…ØªÙ† ÙÚ©Ø± Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†.
        """
        aggregated_thought = self._call_llm(prompt, "Ø´Ù…Ø§ ÛŒÚ© Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒØ³Øª Ùˆ ØªØ±Ú©ÛŒØ¨â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ Ù‡Ø³ØªÛŒØ¯.")
        if aggregated_thought:
            score = self.evaluate_thought_quality(aggregated_thought)
            self._add_node(aggregated_thought, score, parent=[node_id_1, node_id_2], op="aggregate")

    def solve(self, cycles=3):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ø§Ø³ØªØ¯Ù„Ø§Ù„."""
        # ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ: Ø¨Ø±Ø±Ø³ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø³ØªØ¯Ù„Ø§Ù„
        if not self._needs_complex_reasoning():
            print("\nğŸš¦ Ù†ØªÛŒØ¬Ù‡ ØªØ´Ø®ÛŒØµ: Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ Ø¨Ù‡ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ù†ÛŒØ§Ø² Ù†Ø¯Ø§Ø±Ø¯. (NO THINK)")
            # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§Ø² Ù…Ø¯Ù„ Ø¨Ø®ÙˆØ§Ù‡ÛŒØ¯ Ø¨Ù‡ Ø³ÙˆØ§Ù„ Ø³Ø§Ø¯Ù‡ Ù¾Ø§Ø³Ø® Ø¯Ù‡Ø¯
            # direct_answer = self._call_llm(self.problem)
            # print(f"Ù¾Ø§Ø³Ø® Ù…Ø³ØªÙ‚ÛŒÙ…: {direct_answer}")
            return

        print("\nğŸš¦ Ù†ØªÛŒØ¬Ù‡ ØªØ´Ø®ÛŒØµ: Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ Ø¨Ù‡ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯. Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ú¯Ø±Ø§Ù ÙÚ©Ø±...")

        print("\n--- Ù…Ø±Ø­Ù„Ù‡ Û±: ØªÙˆÙ„ÛŒØ¯ Ø§ÙÚ©Ø§Ø± Ø§ÙˆÙ„ÛŒÙ‡ ---")
        self.generate_initial_thoughts()

        for i in range(cycles):
            print(f"\n--- Ù…Ø±Ø­Ù„Ù‡ {i + 2}: Ø´Ø±ÙˆØ¹ Ú†Ø±Ø®Ù‡ Ø§Ø³ØªØ¯Ù„Ø§Ù„ {i + 1}/{cycles} ---")
            sorted_nodes = sorted(self.graph.items(), key=lambda item: item[1]['score'], reverse=True)
            if len(sorted_nodes) < 2: break

            best_node_id = sorted_nodes[0][0]
            self.refine_thought(best_node_id)

            node1_id, node2_id = sorted_nodes[0][0], sorted_nodes[1][0]
            self.aggregate_thoughts(node1_id, node2_id)

        print("\n--- Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØª ---")
        self.show_best_solution()

    def show_best_solution(self):
        """Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ±ÛŒÙ† ÙÚ©Ø± ÛŒØ§ Ø±Ø§Ù‡â€ŒØ­Ù„ Ù†Ù‡Ø§ÛŒÛŒ."""
        if len(self.graph) <= 1:
            print("Ù‡ÛŒÚ† Ø±Ø§Ù‡â€ŒØ­Ù„ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯.")
            return

        # Ø­Ø°Ù Ú¯Ø±Ù‡ Ø±ÛŒØ´Ù‡ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ø§Øª
        valid_nodes = {k: v for k, v in self.graph.items() if k != 'root'}
        if not valid_nodes: return

        best_node = max(valid_nodes.items(), key=lambda item: item[1]['score'])
        print("\nğŸ† Ø¨Ù‡ØªØ±ÛŒÙ† ÙÚ©Ø± ÛŒØ§ Ø±Ø§Ù‡â€ŒØ­Ù„ ÛŒØ§ÙØªâ€ŒØ´Ø¯Ù‡:")
        print(f"   Ø§Ù…ØªÛŒØ§Ø²: {best_node[1]['score']:.2f}")
        print(f"   Ø±Ø§Ù‡â€ŒØ­Ù„: \"{best_node[1]['thought']}\"")

# --- Ù†Ø­ÙˆÙ‡ Ø§Ø¬Ø±Ø§ ---
if __name__ == "__main__":
    try:
        # Ø§ØªØµØ§Ù„ Ø¨Ù‡ API
        openai_client = OpenAI(
            
           
            api_key="API",
            base_url="Ø³Ø§ÛŒØª Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡Ù†Ø¯Ù‡ API",
        )

        # Û±. Ù…Ø³Ø¦Ù„Ù‡ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯
        
        PROBLEM_STATEMENT ="Ù…Ø³Ø¦Ù„Ù‡ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯"
        # Û². Ø³Ø§Ø®Øª Ùˆ Ø§Ø¬Ø±Ø§ÛŒ Ù…ÙˆØªÙˆØ± Ø§Ø³ØªØ¯Ù„Ø§Ù„
        reasoner = GoT_Reasoner(
            client=openai_client,
            model_name="Ù†Ø§Ù… Ù…Ø¯Ù„",
            problem_statement=PROBLEM_STATEMENT
        )
        reasoner.solve(cycles=2) # ØªØ¹Ø¯Ø§Ø¯ Ú†Ø±Ø®Ù‡â€ŒÙ‡Ø§ÛŒ ÙÚ©Ø± Ú©Ø±Ø¯Ù†

    except Exception as e:
        print(f"âŒ ÛŒÚ© Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø® Ø¯Ø§Ø¯: {e}")